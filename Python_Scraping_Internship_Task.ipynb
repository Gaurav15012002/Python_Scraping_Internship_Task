{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining all the required functions\n",
    "\n",
    "#Function to extract Product Name \n",
    "def get_pdt_name(soup):\n",
    "\n",
    "    try:\n",
    "        pdt_name_string = soup.find(\"span\", attrs = {\"id\": 'productTitle'}).text.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        pdt_name_string = \"\"\n",
    "\n",
    "    return pdt_name_string\n",
    "\n",
    "# Function to extract Product Price\n",
    "def get_pdt_price(soup):\n",
    "\n",
    "    try:\n",
    "        pdt_price = soup.find(\"span\", attrs = {'class': 'a-price aok-align-center reinventPricePriceToPayMargin priceToPay'}).find(\"span\", attrs = {'class': 'a-price-whole'}).text.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        pdt_price = \"\"\n",
    "\n",
    "    return pdt_price\n",
    "\n",
    "# Function to extract Product Rating\n",
    "def get_pdt_rating(soup):\n",
    "\n",
    "    try:\n",
    "        pdt_rating = soup.find(\"span\", attrs = {'class': 'a-icon-alt'}).text.strip()\n",
    "    \n",
    "    except AttributeError:\n",
    "        pdt_rating = \"\"\n",
    "            \n",
    "    return pdt_rating\n",
    "\n",
    "# Function to extract Seller Name\n",
    "def get_pdt_seller_name(soup):\n",
    "    try:\n",
    "        pdt_seller_name = soup.find(\"div\", attrs = {\"id\": 'merchant-info'}).find(\"a\", attrs = {\"class\": 'a-link-normal'}).find(\"span\").text\n",
    "\n",
    "    except AttributeError:\n",
    "        pdt_seller_name = \"\"\n",
    "\n",
    "    return pdt_seller_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    # add our user agent \n",
    "    HEADERS = ({'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36', 'Accept-Language': 'en-US, en;q=0.5'})\n",
    "\n",
    "    # The URL of webpage to be extracted\n",
    "    url = \"https://www.amazon.in/s?rh=n%3A6612025031&fs=true&ref=lp_6612025031_sar\"\n",
    "\n",
    "    # HTTP Request\n",
    "    req = requests.get(url, headers = HEADERS)\n",
    "\n",
    "    # Soup Object containing all the data\n",
    "    soup1 = BeautifulSoup(req.content, \"html.parser\")\n",
    "\n",
    "    # Fetch links as List of Tag Objects\n",
    "    pdt_links = soup.find_all(\"a\", attrs = {'class': 'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal'})\n",
    "\n",
    "    # Storing the links of each product\n",
    "    pdt_links_list = []\n",
    "\n",
    "    # Loop for extracting links from Tag Objects defined earlier\n",
    "    for pdt_link in pdt_links:\n",
    "            pdt_links_list.append(pdt_link.get('href'))\n",
    "\n",
    "    #Defining dictionary to store the required data\n",
    "    dict1 = {\"PDT_NAME\": [], \"PDT_PRICE\": [], \"PDT_RATING\":[], \"PDT_SELLER_NAME\": []}\n",
    "    \n",
    "    # Loop for extracting product details from each link \n",
    "    for pdt_link in pdt_links_list:\n",
    "        new_req = requests.get(\"https://www.amazon.in\" + pdt_link, headers = HEADERS)\n",
    "        new_soup1 = BeautifulSoup(new_req.content, \"html.parser\")\n",
    "\n",
    "        # Function calls to display all necessary product information\n",
    "        dict1['PDT_NAME'].append(get_pdt_name(new_soup1))\n",
    "        dict1['PDT_PRICE'].append(get_pdt_price(new_soup1))\n",
    "        dict1['PDT_RATING'].append(get_pdt_rating(new_soup1))\n",
    "        dict1['PDT_SELLER_NAME'].append(get_pdt_seller_name(new_soup1))\n",
    "    \n",
    "    #Converting dictionary to csv file\n",
    "    amazon_data_df = pd.DataFrame.from_dict(dict1)\n",
    "    amazon_data_df['PDT_NAME'].replace('', np.nan, inplace = True)\n",
    "    amazon_data_df = amazon_data_df.dropna(subset = ['PDT_NAME'])\n",
    "    amazon_data_df.to_csv(\"amazon_data_df_pdt.csv\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
